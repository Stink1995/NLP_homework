{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compared to FNN, what is the biggest advantage of CNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与FNN相比，CNN最大的特点就是能够自动选择出最重要的特征，不需要人为的进行特征的选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Suppose your input is a 100 by 100 gray image, and you use a convolutional layer with 50 filters that are each 5x5. How many parameters does this hidden layer have (including the bias parameters)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 92500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.What are \"local invariant\" and \"parameter sharing\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"local invariant\" : 广义的局部不变量是用来在局部区分具有某种结构的流形的量。例如，在欧几里德平面上，给定两个半径不等的圆，\n",
    "# 我们可以通过局部不变量（半径的倒数，即曲率）来区分它们。\n",
    "# \"parameter sharing\" : 在卷积神经网络中，没计算出一个数据窗口内的局部数据后，数据窗口不断平移滑动，直到计算完所有的数据，\n",
    "# 在这个移动的过程中参数w保持不变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Why we use batch normalization ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用批量标准化可以提高学习率，提高网络训练的速度。使权重更容易初始化-权重初始化可能很困难，尤其是在创建更深的网络时。\n",
    "# 批量标准化有助于降低对初始权重的敏感度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What problem does dropout try to solve ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout是为了降低过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Is the following statement correct and why ? \"Because pooling layers do not have parameters, they do not affect the backpropagation(derivatives) calculation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False\n",
    "# 在前向传播中pooling layers保存了卷积层的最大值/平均值，在反向传播时，如果pooling layers不对梯度产生影响的话，那么相当于\n",
    "# 在pooling layers的梯度为0，那么梯度在此中断，梯度不会再更新，达不到更新参数的作用，因此pooling layers会对反向传播产生影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
